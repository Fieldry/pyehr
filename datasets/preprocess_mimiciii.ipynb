{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on https://github.com/YerevaNN/mimic3-benchmarks & https://github.com/kaggarwal/ClinicalNotesICU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from mimic3models.in_hospital_mortality import utils as ihm_utils\n",
    "from mimic3benchmark.readers import InHospitalMortalityReader\n",
    "from mimic3models.preprocessing import Discretizer, Normalizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./datasets/mimiciii/\"\n",
    "ihm_dir = 'data/in-hospital-mortality/'\n",
    "ihm_normalizer_state = 'mimic3models/in_hospital_mortality/ihm_ts1.0.input_str_previous.start_time_zero.normalizer'\n",
    "timestep = 1.0\n",
    "imputation = 'previous'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build readers, discretizers, normalizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reader = InHospitalMortalityReader(dataset_dir=os.path.join(ihm_dir, 'train'),\n",
    "                                   listfile=os.path.join(\n",
    "                                   ihm_dir, 'train', 'listfile.csv'),\n",
    "                                   period_length=48.0)\n",
    "\n",
    "test_reader = InHospitalMortalityReader(dataset_dir=os.path.join(ihm_dir, 'test'),\n",
    "                                   listfile=os.path.join(\n",
    "                                   ihm_dir, 'test', 'listfile.csv'),\n",
    "                                   period_length=48.0)\n",
    "\n",
    "discretizer = Discretizer(timestep=float(timestep),\n",
    "                          store_masks=True,\n",
    "                          impute_strategy=imputation,\n",
    "                          start_time='zero')\n",
    "\n",
    "discretizer_header = discretizer.transform(\n",
    "    train_reader.read_example(0)[\"X\"])[1].split(',')\n",
    "\n",
    "cont_channels = [i for (i, x) in enumerate(\n",
    "    discretizer_header) if x.find(\"->\") == -1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose here which columns to standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer(fields=cont_channels)\n",
    "normalizer_state = ihm_normalizer_state\n",
    "if normalizer_state is None:\n",
    "    normalizer_state = 'ihm_ts{}.input_str_{}.start_time_zero.normalizer'.format(\n",
    "        timestep, imputation)\n",
    "    normalizer_state = os.path.join(\n",
    "        os.path.dirname(__file__), normalizer_state)\n",
    "normalizer.load_params(normalizer_state)\n",
    "\n",
    "normalizer = None\n",
    "train_ihm = ihm_utils.load_data(\n",
    "    train_reader, discretizer, normalizer, small_part=False, return_names=True)\n",
    "\n",
    "test_ihm = ihm_utils.load_data(\n",
    "    test_reader, discretizer, normalizer, small_part=False, return_names=True)\n",
    "\n",
    "print(\"Number of train_ihm_names: \", len(train_ihm['names']))\n",
    "print(\"Number of test_ihm_names: \", len(test_ihm['names']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(data_dir, 'ihm')\n",
    "\n",
    "with open(os.path.join(save_dir, 'train.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_ihm['data'], f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(os.path.join(save_dir, 'test.pkl'), 'wb') as f:\n",
    "    pickle.dump(test_ihm['data'], f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
